ğŸ“Š AnÃ¡lisis de Datos con Pandas, NumPy & SciPy
Paso 1: IngenierÃ­a de CaracterÃ­sticas Avanzada
Este proyecto implementa un pipeline de transformaciÃ³n y anÃ¡lisis de datos utilizando herramientas avanzadas del ecosistema cientÃ­fico de Python.
TecnologÃ­as utilizadas
Pandas â†’ Merge complejo y window functions (rolling 48h)
NumPy â†’ Target Encoding vectorizado (sin bucles for)
SciPy â†’ Filtro Savitzkyâ€“Golay y test estadÃ­stico Kolmogorovâ€“Smirnov
El objetivo es generar features avanzadas listas para modelado o anÃ¡lisis exploratorio.

ğŸ“ Estructura del Proyecto:
analisis-datos-pandas-numpy/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pipeline_paso1.py
â”œâ”€â”€ data/
â”œâ”€â”€ reports/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ InstalaciÃ³n:
1ï¸âƒ£ Crear entorno virtual (python -m venv .venv)
2ï¸âƒ£ Activar entorno virtual (.\.venv\Scripts\Activate.ps1)
3ï¸âƒ£ Instalar dependencias (pip install -r requirements.txt)

ğŸš€ Ejecutar Paso 1 
EjecuciÃ³n bÃ¡sica (python src/pipeline_paso1.py)
EjecuciÃ³n con parÃ¡metros personalizados (python src/pipeline_paso1.py --n_users 5000 --n_tx 200000 --seed 42)

ParÃ¡metros disponibles: 
--n_users â†’ cantidad de usuarios
--n_tx â†’ cantidad de transacciones
--seed â†’ semilla para reproducibilidad

ğŸ§  Funcionalidades Implementadas

âœ” GeneraciÃ³n de datos sintÃ©ticos
âœ” Merge validado (many_to_one)
âœ” Feature amount = price * volume
âœ” Rolling 48h por usuario (avg_amount_48h)
âœ” Target Encoding vectorizado (segment_te)
âœ” Suavizado Savitzkyâ€“Golay (price_smooth)
âœ” KS Test (normal vs sospechosa)
âœ” OptimizaciÃ³n de tipos
âœ” Validaciones de calidad de datos
âœ” Export de dataset y reportes

ğŸ“¤ Archivos Generados
Al ejecutar el pipeline se generan:

data/paso1_features.csv
reports/paso1_reporte.txt
reports/data_quality_summary.csv
reports/data_quality_nulls.csv

âœ… VerificaciÃ³n 
La ejecuciÃ³n correcta debe mostrar en terminal:

Shapes de usuarios y transacciones
ConfirmaciÃ³n de columnas generadas
Resultado del KS test (stat y p-value)
ValidaciÃ³n de duplicados y nulos

ğŸ“ Historial de Desarrollo
Estructura base
GeneraciÃ³n de datos
Merge y features
Rolling 48h
Target Encoding
Suavizado con SciPy
KS Test
Reportes y validaciones
Correcciones finales


ğŸ”œ PrÃ³ximo Paso
Paso 2: VisualizaciÃ³n de Alta Dimensionalidad
ReducciÃ³n de dimensionalidad (t-SNE o UMAP)
VisualizaciÃ³n con Seaborn
RepresentaciÃ³n de mÃºltiples variables en 2D

ğŸ“Š Paso 2: VisualizaciÃ³n de Alta Dimensionalidad (Matplotlib & Seaborn)
ğŸ¯ Objetivo

Visualizar datos de alta dimensionalidad (>3 dimensiones) mediante reducciÃ³n a 2 componentes y modelado supervisado.

Se implementa:
- ğŸ”¹ ReducciÃ³n de dimensionalidad con **t-SNE (Scikit-learn)**
- ğŸ”¹ VisualizaciÃ³n con **Seaborn (color = price, tamaÃ±o = volume)**
- ğŸ”¹ Modelo de clasificaciÃ³n (Logistic Regression)
- ğŸ”¹ Superficie de decisiÃ³n
- ğŸ”¹ Curva de aprendizaje (Loss vs Epochs)
- ğŸ”¹ Curva en tiempo real (GIF)
- ğŸ”¹ Dashboard final 2x2 (Matplotlib)
- ğŸ”¹ ExportaciÃ³n de mÃ©tricas en CSV

ğŸ“ Estructura del Proyecto:
src/
 â”œâ”€â”€ pipeline_paso1.py
 â”œâ”€â”€ paso2_visualizacion.py
 â””â”€â”€ paso2_modelo.py

ğŸ“¦ Requisitos

Python 3.10+

Instalar dependencias:

```bash
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```
â–¶ Ejecutar Paso 2:
python src/paso2_modelo.py

EjecuciÃ³n personalizada:
python src/paso2_modelo.py --epochs 15 --sample 20000

Opciones disponibles:
Argumento	DescripciÃ³n
--epochs	NÃºmero de Ã©pocas para SGDClassifier
--sample	TamaÃ±o de muestra para entrenamiento
--no-show	No abrir imÃ¡genes automÃ¡ticamente

ğŸ“ Archivos generados

Se guardan en la carpeta reports/:
paso2_decision_surface.png
paso2_learning_curve_realtime.gif
paso2_2x2_dashboard.png
paso2_reporte.txt
paso2_reporte.html
paso2_metrics.csv

ğŸ“ˆ DescripciÃ³n tÃ©cnica
ğŸ”¹ ReducciÃ³n de dimensionalidad
Se utiliza TSNE de Scikit-learn para transformar mÃºltiples variables numÃ©ricas en 2 componentes visualizables.

ğŸ”¹ VisualizaciÃ³n
Se utiliza Seaborn scatterplot donde:
Color representa el precio (price)
TamaÃ±o del punto representa el volumen (volume)

ğŸ”¹ Modelo
Se entrena:
Logistic Regression (modelo base)
SGDClassifier para curva de aprendizaje

ğŸ”¹ Dashboard 2x2 incluye:
Scatter PCA 2D
Superficie de decisiÃ³n
Curva Loss vs Epochs
DistribuciÃ³n de precios

ğŸ§ª Evidencia reproducible

El proyecto puede clonarse y ejecutarse desde cero:
git clone <URL_DEL_REPOSITORIO>
cd analisis-datos-pandas-numpy
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
python src/paso2_modelo.py

âœ… Resultado
El Paso 2 cumple con:
VisualizaciÃ³n de alta dimensionalidad
Modelado supervisado
Subplots 2x2 requeridos
Curva de aprendizaje en tiempo real
ExportaciÃ³n de mÃ©tricas

ğŸ§  Flujo de ejecuciÃ³n del Paso 2
1. Se cargan las features generadas en Paso 1.
2. Se reduce dimensionalidad con t-SNE.
3. Se entrena modelo base (Logistic Regression).
4. Se genera superficie de decisiÃ³n.
5. Se entrena SGDClassifier por Ã©pocas.
6. Se construye dashboard 2x2.
7. Se exportan mÃ©tricas y reportes.